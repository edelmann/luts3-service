This document intends to gave an overview of the SGAS LUTS system.

The SGAS LUTS system is intended for accounting infrastructure in grid and HPC
systems.



1: Terminology & Concepts


* Usage Record

An XML document adhering the OGF-98 standard. The document describes the job
and consumed resource for a job run on a grid or cluster. Most accounting
systems use a number of extensions for the OGF standard to describe additional
information.

Usage Records is typically abbreviated to UR.


* LUTS service:

A service to which usage records can be registered to and stored at. Aggregated
information can then be extracted from the LUTS service through views.

Typically a single LUTS would be run per-country or per-vo basis, but it can
differ. It is also possible to run a LUTS per site, however this might incur a
lot of additional adminstration time. The options can also be combined in
various ways, e.g., having a per-site LUTS and a national LUTS. Note that the
LUTS does not feature forwarding of usage records. Instead the registration
client simply registers URs to multple places. This scheme is significantly
simpler and less brittle than forwarding.

Currently NDGF runs a single LUTS to which all ATLAS and ALICE production sites
report to. In the future it is planned/hoped that the NGIs will run national
LUTSes, and that only ATLAS, ALICE, CMS URs will get logged to the LUTS run by
NDGF.


* UR Logger:

A program/plugin generating usage records. Typically installed/deployed
alongside a grid middleware or LRMS.

While the usage record could be registered immediately it is typically written
to disk in a spool directory and then registered to one or more LUTSes by
another program, typically called UR registrant.

The ARC middleware includes a UR logger (and registrant) as of version 0.8.1.

NDGF is also running a custom UR logger for MonALISA (the information system of
the AliEn production system/grid).

NDGF is working on producing UR loggers for LRMSes. Currently Maui is underway
as the first target. Code is available at: http://github.com/htj/lrmsurgen

The three loggers all use the same registrant code (except some minor
differences). The current registrant supports registering URs to multiple
LUTSes, per-VO registration and will retry registration if the LUTS is
unavailable. This will also work with multiple LUTSes and so forth.



2. LUTS Service


* Description:

The LUTS service is daemon listening on port 6143 by default. The
interface/protocol is TLS+HTTP, and is used for registering URs and accessing
views (can be done via browser or view data can be fetched using ordinary HTTP
client libraries).

The LUTS service is essentially a thin wrapper over a database (the server code
is only ~1500 lines). It performs mainly authorization and data transformation.
Proxy certificates are not yet supported, but host certificates (for
registration), and ordinary grid user certificates (for accessing view in in the
browser), works fine.

The underlying database is CouchDB, a document-oriented JSON database. It has a
web page at: http://couchdb.apache.org/


* Insertion

Once the LUTS has received a batch of URs, the usage records are transformed
into JSON documents before being inserted into the database (which is JSON
based). Information about insert time, certificate used in authorization and
from which host the usage record was inserted is added as "provenance"
information the usage records.

An _id field (the reference for the document in the database) is added to the
JSON document. Currently this is a SHA224 hash of the global_job_id value. This
may change in the future, as it is rather inefficient for view creation.


* Views

Note: The view engine in SGAS is not yet deemed ready for general usage, but it
can still be very useful.

Just inserting usage records in itself is rather useless. In order to provide
high level information about the usage record data, SGAS provides access to
aggregated information in the form of views. It is also possible to access
individual usage records, but this is typically rather meaningless (as studying
a drop in an ocean).

SGAS tries to push as much view functionality to CouchDB, as the database is
closest to the data  Often SGAS will just pass the data directly though it, or
do some basic data transformation.


